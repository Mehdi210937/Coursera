{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Web Scraping Successful! Data saved to 'spacex_launches_scraped.csv'\n",
      "  Date and time (UTC) Version,booster[f]             Launch site  \\\n",
      "1  18 March 202518:09              F9 B5  Cape Canaveral, SLC‑40   \n",
      "2  20 March 202506:02              F9 B5      Vandenberg, SLC‑4E   \n",
      "3  22 March 202520:45              F9 B5      Vandenberg, SLC‑4E   \n",
      "4          March 2025              F9 B5                TBA (FL)   \n",
      "5          March 2025       F9 B5B1085.6                TBA (FL)   \n",
      "\n",
      "                                          Payload[g]      Orbit    Customer  \n",
      "1                              Starlink: Group 12-25        LEO      SpaceX  \n",
      "2  NROL-57 (unknown number of Starshield satellites)        LEO         NRO  \n",
      "3                               Starlink: Group 11-7        LEO      SpaceX  \n",
      "4              Fram2 (Crew Dragon C207.4 Resilience)  Polar LEO   Chun Wang  \n",
      "5                                         CRS SpX-32  LEO (ISS)  NASA (CRS)  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_Falcon_9_and_Falcon_Heavy_launches\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    tables = soup.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "    launch_table = tables[3] \n",
    "\n",
    "    headers = [header.text.strip() for header in launch_table.find_all(\"th\")]\n",
    "\n",
    "    rows = []\n",
    "    for row in launch_table.find_all(\"tr\"):\n",
    "        cells = row.find_all([\"th\", \"td\"])\n",
    "        row_data = [cell.text.strip().replace(\"\\n\", \" \") for cell in cells]\n",
    "\n",
    "        if len(row_data) == len(headers):\n",
    "            rows.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    df = df[~df[\"Date and time (UTC)\"].str.contains(\"Date\", na=False)]  \n",
    "\n",
    "    df.to_csv(\"spacex_launches_scraped.csv\", index=False)\n",
    "\n",
    "    print(\"✅ Web Scraping Successful! Data saved to 'spacex_launches_scraped.csv'\")\n",
    "    print(df.head())\n",
    "\n",
    "else:\n",
    "    print(f\"❌ Error: Unable to fetch data. HTTP Status Code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
